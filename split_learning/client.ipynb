{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/home/bishwa/mambaforge-pypy3/envs/multimodal/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client starts from:  0\n",
      "Files already downloaded and verified\n",
      "Train Size (x, y): \n",
      "torch.Size([4, 3, 32, 32]) \n",
      " torch.Size([4])\n",
      "Total Batch Size\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "root_path = '../cifar10_data'\n",
    "\n",
    "# Setup cpu\n",
    "device = 'cpu'\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# Setup client order\n",
    "client_order = int(0)\n",
    "print('Client starts from: ', client_order)\n",
    "\n",
    "num_train_data = 50000\n",
    "\n",
    "# Load data\n",
    "from random import shuffle\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "indices = list(range(50000))\n",
    "\n",
    "part_tr = indices[num_train_data * client_order : num_train_data * (client_order + 1)]\n",
    "\n",
    "train_set  = torchvision.datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform)\n",
    "train_set_sub = Subset(train_set, part_tr)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set_sub, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "x_train, y_train = next(iter(train_loader))\n",
    "print('Train Size (x, y): ')\n",
    "print(x_train.size(), '\\n', y_train.size())\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "print('Total Batch Size')\n",
    "print(total_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for communication between client and server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msg_len = recv_all(sock, 4)\n",
    "    if not raw_msg_len:\n",
    "        return None\n",
    "    msg_len = struct.unpack('>I', raw_msg_len)[0]\n",
    "    # read the message data\n",
    "    msg =  recv_all(sock, msg_len)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recv_all(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of client side model (input layer only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # out = self.layer1(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [1, 3, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training hyper parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet20_client = resnet20().to(device)\n",
    "\n",
    "epoch = 1\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet20_client.parameters(), lr = lr, momentum = 0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with SERVER_001:   0%|                                           | 0/12500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with SERVER_001: 100%|███████████████████████████████| 12500/12500 [04:44<00:00, 43.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# host = '10.2.144.188'\n",
    "# host = '10.9.240.14'\n",
    "host = '10.2.143.109'\n",
    "port = 10081\n",
    "epoch = 1\n",
    "\n",
    "s1 = socket.socket()\n",
    "s1.connect((host, port)) # establish connection\n",
    "# s1.close()\n",
    "\n",
    "client_weight = copy.deepcopy(resnet20_client.state_dict()) # init weight of client model.\n",
    "\n",
    "msg = {\n",
    "    'epoch': epoch,\n",
    "    'total_batch': total_batch\n",
    "}\n",
    "\n",
    "send_msg(s1, msg) # send 'epoch' and 'batch size' to server\n",
    "\n",
    "resnet20_client.eval()\n",
    "\n",
    "remote_server = recv_msg(s1) # get server's meta information.\n",
    "\n",
    "for epc in range(1):\n",
    "    print(\"running epoch \", epc)\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(train_loader, ncols=100, desc='Training with {}'.format(remote_server))):\n",
    "        x, label = data\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        output = resnet20_client(x)\n",
    "        client_output = output.clone().detach().requires_grad_(True)\n",
    "\n",
    "        msg = {\n",
    "            'label': label,\n",
    "            'client_output': client_output\n",
    "        }\n",
    "        send_msg(s1, msg) # send label and output(feature) to server\n",
    "        \n",
    "        client_grad = recv_msg(s1) # receive gradaint after the server has completed the back propagation.\n",
    "\n",
    "        output.backward(client_grad) # continue back propagation for client side layers.\n",
    "        optimizer.step()\n",
    "     \n",
    "s1.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
