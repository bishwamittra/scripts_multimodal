{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/home/bishwa/mambaforge-pypy3/envs/multimodal/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from model import ResNet18, ResNet50\n",
    "from utils import get_metrics\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client starts from:  0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train batch shape x: torch.Size([64, 3, 32, 32]) y: torch.Size([64])\n",
      "Num Batch 782\n"
     ]
    }
   ],
   "source": [
    "root_path = '../models/cifar10_data'\n",
    "\n",
    "# Setup cpu\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cuda:1'\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# Setup client order\n",
    "client_order = int(0)\n",
    "print('Client starts from: ', client_order)\n",
    "\n",
    "num_train_data = 50000\n",
    "\n",
    "# Load data\n",
    "from random import shuffle\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "indices = list(range(50000))\n",
    "\n",
    "part_tr = indices[num_train_data * client_order : num_train_data * (client_order + 1)]\n",
    "\n",
    "train_set  = torchvision.datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform)\n",
    "train_set_sub = Subset(train_set, part_tr)\n",
    "train_loader = torch.utils.data.DataLoader(train_set_sub, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root=root_path, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "x_train, y_train = next(iter(train_loader))\n",
    "print(f'Train batch shape x: {x_train.size()} y: {y_train.size()}')\n",
    "total_batch = len(train_loader)\n",
    "print(f'Num Batch {total_batch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training @  Mon Oct 23 14:32:02 2023\n",
      "Epoch: 1/10, Batch: 100/782, Train Loss: 2.42 Train Accuracy: 0.06\n",
      "Epoch: 1/10, Batch: 200/782, Train Loss: 2.37 Train Accuracy: 0.06\n",
      "Epoch: 1/10, Batch: 300/782, Train Loss: 2.38 Train Accuracy: 0.17\n",
      "Epoch: 1/10, Batch: 400/782, Train Loss: 2.14 Train Accuracy: 0.28\n",
      "Epoch: 1/10, Batch: 500/782, Train Loss: 2.27 Train Accuracy: 0.17\n",
      "Epoch: 1/10, Batch: 600/782, Train Loss: 2.16 Train Accuracy: 0.17\n",
      "Epoch: 1/10, Batch: 700/782, Train Loss: 2.05 Train Accuracy: 0.33\n",
      "56.54062104225159\n",
      "Epoch: 2/10, Batch: 100/782, Train Loss: 2.06 Train Accuracy: 0.25\n",
      "Epoch: 2/10, Batch: 200/782, Train Loss: 1.84 Train Accuracy: 0.25\n",
      "Epoch: 2/10, Batch: 300/782, Train Loss: 1.7 Train Accuracy: 0.44\n",
      "Epoch: 2/10, Batch: 400/782, Train Loss: 2.03 Train Accuracy: 0.25\n",
      "Epoch: 2/10, Batch: 500/782, Train Loss: 1.81 Train Accuracy: 0.33\n",
      "Epoch: 2/10, Batch: 600/782, Train Loss: 2.11 Train Accuracy: 0.27\n",
      "Epoch: 2/10, Batch: 700/782, Train Loss: 1.62 Train Accuracy: 0.47\n",
      "56.41061329841614\n",
      "Epoch: 3/10, Batch: 100/782, Train Loss: 1.58 Train Accuracy: 0.38\n",
      "Epoch: 3/10, Batch: 200/782, Train Loss: 1.55 Train Accuracy: 0.38\n",
      "Epoch: 3/10, Batch: 300/782, Train Loss: 1.57 Train Accuracy: 0.42\n",
      "Epoch: 3/10, Batch: 400/782, Train Loss: 1.48 Train Accuracy: 0.47\n",
      "Epoch: 3/10, Batch: 500/782, Train Loss: 1.25 Train Accuracy: 0.59\n",
      "Epoch: 3/10, Batch: 600/782, Train Loss: 1.41 Train Accuracy: 0.52\n",
      "Epoch: 3/10, Batch: 700/782, Train Loss: 1.31 Train Accuracy: 0.58\n",
      "55.22737216949463\n",
      "Epoch: 4/10, Batch: 100/782, Train Loss: 1.09 Train Accuracy: 0.56\n",
      "Epoch: 4/10, Batch: 200/782, Train Loss: 1.29 Train Accuracy: 0.53\n",
      "Epoch: 4/10, Batch: 300/782, Train Loss: 1.18 Train Accuracy: 0.53\n",
      "Epoch: 4/10, Batch: 400/782, Train Loss: 1.14 Train Accuracy: 0.59\n",
      "Epoch: 4/10, Batch: 500/782, Train Loss: 1.22 Train Accuracy: 0.52\n",
      "Epoch: 4/10, Batch: 600/782, Train Loss: 1.3 Train Accuracy: 0.56\n",
      "Epoch: 4/10, Batch: 700/782, Train Loss: 1.4 Train Accuracy: 0.47\n",
      "57.14610695838928\n",
      "Epoch: 5/10, Batch: 100/782, Train Loss: 1.2 Train Accuracy: 0.5\n",
      "Epoch: 5/10, Batch: 200/782, Train Loss: 0.9 Train Accuracy: 0.7\n",
      "Epoch: 5/10, Batch: 300/782, Train Loss: 0.89 Train Accuracy: 0.66\n",
      "Epoch: 5/10, Batch: 400/782, Train Loss: 0.88 Train Accuracy: 0.67\n",
      "Epoch: 5/10, Batch: 500/782, Train Loss: 1.13 Train Accuracy: 0.64\n",
      "Epoch: 5/10, Batch: 600/782, Train Loss: 0.79 Train Accuracy: 0.7\n",
      "Epoch: 5/10, Batch: 700/782, Train Loss: 1.1 Train Accuracy: 0.62\n",
      "57.183300495147705\n",
      "Epoch: 6/10, Batch: 100/782, Train Loss: 0.91 Train Accuracy: 0.7\n",
      "Epoch: 6/10, Batch: 200/782, Train Loss: 0.69 Train Accuracy: 0.75\n",
      "Epoch: 6/10, Batch: 300/782, Train Loss: 0.82 Train Accuracy: 0.78\n",
      "Epoch: 6/10, Batch: 400/782, Train Loss: 0.8 Train Accuracy: 0.7\n",
      "Epoch: 6/10, Batch: 500/782, Train Loss: 0.92 Train Accuracy: 0.69\n",
      "Epoch: 6/10, Batch: 600/782, Train Loss: 0.91 Train Accuracy: 0.66\n",
      "Epoch: 6/10, Batch: 700/782, Train Loss: 1.04 Train Accuracy: 0.67\n",
      "57.29335641860962\n",
      "Epoch: 7/10, Batch: 100/782, Train Loss: 0.41 Train Accuracy: 0.89\n",
      "Epoch: 7/10, Batch: 200/782, Train Loss: 0.55 Train Accuracy: 0.84\n",
      "Epoch: 7/10, Batch: 300/782, Train Loss: 0.7 Train Accuracy: 0.77\n",
      "Epoch: 7/10, Batch: 400/782, Train Loss: 0.72 Train Accuracy: 0.73\n",
      "Epoch: 7/10, Batch: 500/782, Train Loss: 0.62 Train Accuracy: 0.77\n",
      "Epoch: 7/10, Batch: 600/782, Train Loss: 0.51 Train Accuracy: 0.81\n",
      "Epoch: 7/10, Batch: 700/782, Train Loss: 0.73 Train Accuracy: 0.81\n",
      "57.329039096832275\n",
      "Epoch: 8/10, Batch: 100/782, Train Loss: 0.51 Train Accuracy: 0.8\n",
      "Epoch: 8/10, Batch: 200/782, Train Loss: 0.66 Train Accuracy: 0.8\n",
      "Epoch: 8/10, Batch: 300/782, Train Loss: 0.47 Train Accuracy: 0.84\n",
      "Epoch: 8/10, Batch: 400/782, Train Loss: 0.45 Train Accuracy: 0.84\n",
      "Epoch: 8/10, Batch: 500/782, Train Loss: 0.71 Train Accuracy: 0.72\n",
      "Epoch: 8/10, Batch: 600/782, Train Loss: 0.46 Train Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet50(channel=3, num_classes=10).to(device)\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet_model.parameters(), lr = lr, momentum = 0.9)\n",
    "\n",
    "# Start training\n",
    "print(\"Start training @ \", time.asctime())\n",
    "\n",
    "for epc in range(epoch):\n",
    "    start_time = time.time()    \n",
    "    for i, data in enumerate(tqdm(train_loader, ncols=100, desc='Centralized training', disable=True)):\n",
    "        x, label = data\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = resnet_model(x)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            # measure accuracy and record loss\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = (predicted == label).sum().item()\n",
    "            accuracy = correct / len(label)\n",
    "            print(f'Epoch: {epc+1}/{epoch}, Batch: {i+1}/{total_batch}, Train Loss: {round(loss.item(), 2)} Train Accuracy: {round(accuracy, 2)}')\n",
    "\n",
    "        # if (i + 1) % 1000 == 0:\n",
    "        #     test_loss, test_acc, test_auc, test_bal_acc = get_metrics(resnet_model, test_loader, device)\n",
    "        #     print(f'                                           Test Loss: {round(test_loss, 2)} Test Accuracy: {round(test_acc, 2)} Test AUC: {round(test_auc, 2)} Test Balanced Accuracy: {round(test_bal_acc, 2)}')\n",
    "\n",
    "\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
