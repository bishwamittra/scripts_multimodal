{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# # plt.style.use('ggplot')\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# import sys, os\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch, torchvision\n",
    "# from torch.autograd import Function\n",
    "# from torch.autograd import Variable\n",
    "# from torchvision import transforms\n",
    "# from torchvision import models\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "# from itertools import cycle\n",
    "# from itertools import chain\n",
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import specificity_score\n",
    "# from dalib.modules import WarmStartGradientReverseLayer\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saved-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:21:52.036701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 13:21:52.178650: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-30 13:21:52.680456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-30 13:21:52.680519: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-30 13:21:52.680524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/bishwa/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import \\\n",
    "    (\n",
    "        DermDataset, \n",
    "        derm_data, \n",
    "        clinic_train, \n",
    "        clinic_validate, \n",
    "        clinic_test,\n",
    "        dermoscopic_train,\n",
    "        dermoscopic_validate,\n",
    "        dermoscopic_test,\n",
    "        label_train_diag,\n",
    "        label_validate_diag,\n",
    "        label_test_diag,\n",
    "        label_train_crit,\n",
    "        label_validate_crit,\n",
    "        label_test_crit\n",
    "    )   \n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "published-fellow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 1011\n",
      "Number of cases to train: 413\n",
      "Number of cases to validate: 203\n",
      "Number of cases to test: 395\n"
     ]
    }
   ],
   "source": [
    "derm_data.dataset_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arranged-background",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 203 395\n"
     ]
    }
   ],
   "source": [
    "print(len(clinic_train), len(clinic_validate), len(clinic_test))\n",
    "# print(clinic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rural-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize([299, 299]),\n",
    "                                       # transforms.Pad(padding=10, fill=(255, 176, 145)),\n",
    "                                       transforms.RandomCrop([299, 299], padding=20, padding_mode='edge'),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation([-45, 45]),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5 , 0.5 , 0.5), (0.5 , 0.5 , 0.5))])\n",
    "test_transforms = transforms.Compose([transforms.Resize([299, 299]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5 , 0.5 , 0.5), (0.5 , 0.5 , 0.5))\n",
    "])\n",
    "image_transforms = {'train':train_transforms, 'test':test_transforms}\n",
    "\n",
    "train = list(zip(clinic_train, dermoscopic_train, label_train_diag, label_train_crit))\n",
    "train_df = pd.DataFrame(train, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "train_dataset = DermDataset(train_df, transform=image_transforms['train'])\n",
    "\n",
    "validate = list(zip(clinic_validate, dermoscopic_validate, label_validate_diag, label_validate_crit))\n",
    "validate_df = pd.DataFrame(validate, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "validate_dataset = DermDataset(validate_df, transform=image_transforms['test'])\n",
    "\n",
    "test = list(zip(clinic_test, dermoscopic_test, label_test_diag, label_test_crit))\n",
    "test_df = pd.DataFrame(test, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "test_dataset = DermDataset(test_df, transform=image_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8c948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_path</th>\n",
       "      <th>d_path</th>\n",
       "      <th>lab_diag</th>\n",
       "      <th>lab_crit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/release_v0/images/NEL/NEL025.JPG</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel026.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/release_v0/images/NEL/Nel032.jpg</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel033.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/release_v0/images/NEL/NEL036.JPG</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel037.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 2, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/release_v0/images/NEL/Nel084.jpg</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel085.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 2, 0, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/release_v0/images/NEL/NEL088.JPG</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel089.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 2, 0, 2, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>../data/release_v0/images/NEL/Nel067.jpg</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel066.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>../data/release_v0/images/NEL/Nel069.jpg</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel068.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>../data/release_v0/images/NEL/Nel070.jpg</td>\n",
       "      <td>../data/release_v0/images/NEL/Nel071.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>../data/release_v0/images/Ggl/Ggl011.jpg</td>\n",
       "      <td>../data/release_v0/images/Ggl/Ggl012.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>../data/release_v0/images/Fhl/Fhl059.jpg</td>\n",
       "      <td>../data/release_v0/images/Fhl/Fhl060.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       c_path  \\\n",
       "0    ../data/release_v0/images/NEL/NEL025.JPG   \n",
       "1    ../data/release_v0/images/NEL/Nel032.jpg   \n",
       "2    ../data/release_v0/images/NEL/NEL036.JPG   \n",
       "3    ../data/release_v0/images/NEL/Nel084.jpg   \n",
       "4    ../data/release_v0/images/NEL/NEL088.JPG   \n",
       "..                                        ...   \n",
       "408  ../data/release_v0/images/NEL/Nel067.jpg   \n",
       "409  ../data/release_v0/images/NEL/Nel069.jpg   \n",
       "410  ../data/release_v0/images/NEL/Nel070.jpg   \n",
       "411  ../data/release_v0/images/Ggl/Ggl011.jpg   \n",
       "412  ../data/release_v0/images/Fhl/Fhl059.jpg   \n",
       "\n",
       "                                       d_path  lab_diag               lab_crit  \n",
       "0    ../data/release_v0/images/NEL/Nel026.jpg         0  [0, 0, 0, 0, 0, 0, 1]  \n",
       "1    ../data/release_v0/images/NEL/Nel033.jpg         0  [0, 0, 0, 0, 2, 0, 1]  \n",
       "2    ../data/release_v0/images/NEL/Nel037.jpg         0  [0, 0, 2, 0, 0, 0, 0]  \n",
       "3    ../data/release_v0/images/NEL/Nel085.jpg         0  [0, 0, 2, 0, 2, 1, 0]  \n",
       "4    ../data/release_v0/images/NEL/Nel089.jpg         0  [0, 0, 2, 0, 2, 0, 1]  \n",
       "..                                        ...       ...                    ...  \n",
       "408  ../data/release_v0/images/NEL/Nel066.jpg         3  [0, 0, 0, 0, 0, 0, 0]  \n",
       "409  ../data/release_v0/images/NEL/Nel068.jpg         3  [0, 0, 0, 0, 0, 0, 0]  \n",
       "410  ../data/release_v0/images/NEL/Nel071.jpg         3  [0, 0, 0, 0, 0, 0, 0]  \n",
       "411  ../data/release_v0/images/Ggl/Ggl012.jpg         3  [0, 0, 0, 0, 0, 0, 0]  \n",
       "412  ../data/release_v0/images/Fhl/Fhl060.jpg         3  [0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[413 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "false-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from model import \\\n",
    "    (\n",
    "        CNN,\n",
    "        Concate,\n",
    "        Discriminator,\n",
    "        ReconstructionNet\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "featured-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")# (\"cuda:0\")\n",
    "\n",
    "    \n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet501 = models.resnet50(pretrained=True)\n",
    "cnn_c = CNN(resnet50).to(device)\n",
    "cnn_d = CNN(resnet501).to(device)\n",
    "concate_net = Concate().to(device)\n",
    "discriminator = Discriminator().to(device)# 判别分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-buyer",
   "metadata": {},
   "source": [
    "### Attention based reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dated-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_net_c = ReconstructionNet(in_feature=2048 * 2, output_size=(299, 299)).to(device)\n",
    "reconstruct_net_d = ReconstructionNet(in_feature=2048 * 2, output_size=(299, 299)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba2fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "international-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "learning_rate_re = 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt_list = chain(cnn_c.parameters(), cnn_d.parameters(), concate_net.parameters(), reconstruct_net_c.parameters(), reconstruct_net_d.parameters(), discriminator.parameters())\n",
    "# optimizer = optim.Adam(chain(reconstruct_net_c.parameters(), reconstruct_net_d.parameters(), concate_net.parameters(), cnn_c.parameters(), cnn_d.parameters()), lr=learning_rate , weight_decay=0.0001) #\n",
    "optimizer = optim.Adam(opt_list, lr=learning_rate, weight_decay=0.0001) # , weight_decay=0.0001\n",
    "# optimizer_con = optim.Adam(chain(concate_net.parameters(), discriminator.parameters()), lr=learning_rate) # , weight_decay=0.0001\n",
    "# optimizer_re = optim.Adam(chain(reconstruct_net_c.parameters(), reconstruct_net_d.parameters()), lr=learning_rate_re) # , weight_decay=0.0001\n",
    "# criterion_recon = nn.MSELoss()\n",
    "criterion_recon = nn.MSELoss(reduction='none')\n",
    "criterion_l1 = nn.L1Loss(reduction='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continent-breath",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import \\\n",
    "    (\n",
    "        train_func,\n",
    "        test_func,\n",
    "        metric,\n",
    "        get_average_acc,\n",
    "        get_average_auc,\n",
    "        get_confusion_matrix,\n",
    "        get_specificity,\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5e096fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 begin train...\n",
      "Epoch: 0 train loss, Diag loss: 1.3536, PN loss: 1.0948, STR loss: 0.8821, PIG loss: 0.9458, RS loss: 0.5660, DaG loss: 1.0698, BWV loss: 0.5117, VS loss: 0.6803\n",
      "0.6180379746835443 0.5404092217795586\n",
      "Train metics on epoch 0:\n",
      "{'diag': {0: 0.7274076517150396, 1: 0.2728310502283105, 2: 0.3829729911766687, 3: 0.4559154929577465, 4: 0.3437849944008958, 'micro': 0.757263259093094, 'macro': 0.43867034365317836}, 'pn': {0: 0.492731466580839, 1: 0.4362381030973207, 2: 0.5125329345581429, 'micro': 0.5505399775676975, 'macro': 0.48241649800895425}, 'str': {0: 0.5188067444876783, 1: 0.5395622895622896, 2: 0.5360853891284372, 'micro': 0.7716103188591571, 'macro': 0.533791996215409}, 'pig': {0: 0.5662999269996871, 1: 0.557696926032661, 2: 0.5962385430305917, 'micro': 0.7423489825348502, 'macro': 0.575578331880386}, 'rs': {0: 0.6643925050597376, 1: 0.6643925050597376, 'micro': 0.7962506008652459, 'macro': 0.6674258948520413}, 'dag': {0: 0.5520338983050848, 1: 0.5047420914152848, 2: 0.552195096667185, 'micro': 0.6037013299150777, 'macro': 0.5381283408296451}, 'bwv': {0: 0.4280833333333333, 1: 0.42808333333333337, 'micro': 0.7880019227687869, 'macro': 0.43200698784722225}, 'vs': {0: 0.5827164341930959, 1: 0.6354003139717425, 2: 0.49954337899543383, 'micro': 0.8686941195321263, 'macro': 0.5756242518616693}}\n",
      "{'diag': 0.5544303797468354, 'pn': 0.3822784810126582, 'str': 0.6506329113924051, 'pig': 0.5670886075949367, 'rs': 0.7367088607594937, 'dag': 0.4506329113924051, 'bwv': 0.810126582278481, 'vs': 0.7924050632911392}\n",
      "Current best average ACC: 0.6180\n",
      "Current average AUC: 0.5404\n",
      "\n",
      "Epoch 1 begin train...\n",
      "Epoch: 1 train loss, Diag loss: 1.2785, PN loss: 1.0851, STR loss: 0.8471, PIG loss: 0.8988, RS loss: 0.5516, DaG loss: 1.0593, BWV loss: 0.4810, VS loss: 0.6236\n",
      "0.6132911392405063 0.6215684688340971\n",
      "Train metics on epoch 1:\n",
      "{'diag': {0: 0.7988126649076517, 1: 0.371030510585305, 2: 0.3759008553916616, 3: 0.4510563380281691, 4: 0.5558510638297872, 'micro': 0.7862249639480853, 'macro': 0.512530659344942}, 'pn': {0: 0.4864821371097522, 1: 0.4435000275072894, 2: 0.5930000712098555, 'micro': 0.5696138439352668, 'macro': 0.5094393554866541}, 'str': {0: 0.6295043139908645, 1: 0.6394716394716395, 2: 0.5806177988266064, 'micro': 0.7994199647492388, 'macro': 0.6186592406084341}, 'pig': {0: 0.6898790280529774, 1: 0.6843780019212296, 2: 0.7105999285799308, 'micro': 0.7787950648934465, 'macro': 0.6971659527676635}, 'rs': {0: 0.6997780244173141, 1: 0.699778024417314, 'micro': 0.8101137638199006, 'macro': 0.7027721200905046}, 'dag': {0: 0.5529830508474576, 1: 0.5673376980970446, 2: 0.5604105115845126, 'micro': 0.6226662393847139, 'macro': 0.5621122363806285}, 'bwv': {0: 0.5795416666666667, 1: 0.5795416666666666, 'micro': 0.8345970197083802, 'macro': 0.5842361653645833}, 'vs': {0: 0.72625262993844, 1: 0.7482058757568962, 2: 0.6385388127853882, 'micro': 0.9034770068899214, 'macro': 0.7078386578179856}}\n",
      "{'diag': 0.5544303797468354, 'pn': 0.3493670886075949, 'str': 0.6506329113924051, 'pig': 0.5645569620253165, 'rs': 0.7341772151898734, 'dag': 0.4506329113924051, 'bwv': 0.810126582278481, 'vs': 0.7924050632911392}\n",
      "Current best average ACC: 0.6133\n",
      "Current average AUC: 0.6216\n",
      "\n",
      "Epoch 2 begin train...\n",
      "Epoch: 2 train loss, Diag loss: 1.2370, PN loss: 1.0484, STR loss: 0.8368, PIG loss: 0.8574, RS loss: 0.5288, DaG loss: 1.0236, BWV loss: 0.4575, VS loss: 0.5716\n",
      "0.6246835443037975 0.7099668562029811\n",
      "Train metics on epoch 2:\n",
      "{'diag': {0: 0.6330804749340369, 1: 0.44507575757575757, 2: 0.4343301677106486, 3: 0.5718309859154929, 4: 0.5317749160134378, 'micro': 0.8021246595096942, 'macro': 0.5251904156049932}, 'pn': {0: 0.5966634481278832, 1: 0.5474225669802497, 2: 0.663889482304351, 'micro': 0.6293190193879187, 'macro': 0.6045162387104281}, 'str': {0: 0.6505667399763153, 1: 0.6328671328671328, 2: 0.6272354562804834, 'micro': 0.8084121134433584, 'macro': 0.6392642190980756}, 'pig': {0: 0.7837105016164355, 1: 0.7629682997118156, 2: 0.7845494583978097, 'micro': 0.8040089729210063, 'macro': 0.7790548161385586}, 'rs': {0: 0.7573284585754392, 1: 0.7573284585754391, 'micro': 0.832687069379907, 'macro': 0.7606295825609912}, 'dag': {0: 0.6686440677966102, 1: 0.628862509943095, 2: 0.6737158554916292, 'micro': 0.6764492869732415, 'macro': 0.6590544889407929}, 'bwv': {0: 0.7219166666666667, 1: 0.7219166666666665, 'micro': 0.8783976926774554, 'macro': 0.7254879014756943}, 'vs': {0: 0.8451258474246085, 1: 0.8663938102713613, 2: 0.7982648401826484, 'micro': 0.9360455055279602, 'macro': 0.8388998011585503}}\n",
      "{'diag': 0.5544303797468354, 'pn': 0.4151898734177215, 'str': 0.6531645569620254, 'pig': 0.5822784810126582, 'rs': 0.7291139240506329, 'dag': 0.4607594936708861, 'bwv': 0.810126582278481, 'vs': 0.7924050632911392}\n",
      "Current best average ACC: 0.6247\n",
      "Current average AUC: 0.7100\n",
      "\n",
      "Epoch 3 begin train...\n",
      "Epoch: 3 train loss, Diag loss: 1.2392, PN loss: 1.0240, STR loss: 0.7980, PIG loss: 0.8307, RS loss: 0.4904, DaG loss: 1.0098, BWV loss: 0.4628, VS loss: 0.5545\n",
      "0.6386075949367089 0.7472895941395723\n",
      "Train metics on epoch 3:\n",
      "{'diag': {0: 0.6009234828496043, 1: 0.4565172270651723, 2: 0.3920657371859635, 3: 0.5643661971830986, 4: 0.46570548712206045, 'micro': 0.7974315013619613, 'macro': 0.4977463139641437}, 'pn': {0: 0.6170475270893682, 1: 0.6074159652307862, 2: 0.71701203446557, 'micro': 0.6627078993751001, 'macro': 0.6491453280691173}, 'str': {0: 0.7384255343145549, 1: 0.7287619787619787, 2: 0.72107160528734, 'micro': 0.8344464028200609, 'macro': 0.7315829726357557}, 'pig': {0: 0.8269631869850871, 1: 0.7305475504322766, 2: 0.8409713129389358, 'micro': 0.8170197083800673, 'macro': 0.8018077527048248}, 'rs': {0: 0.8640399556048834, 1: 0.8640399556048834, 'micro': 0.8753468995353308, 'macro': 0.8668691268530625}, 'dag': {0: 0.6775932203389831, 1: 0.6488098880254544, 2: 0.7102835225211216, 'micro': 0.6948341611921167, 'macro': 0.681033801955671}, 'bwv': {0: 0.6589166666666667, 1: 0.6589166666666667, 'micro': 0.8590161833039577, 'macro': 0.6632655056423612}, 'vs': {0: 0.8667887477596821, 1: 0.8559654631083203, 2: 0.8649315068493151, 'micro': 0.940291619932703, 'macro': 0.8651251027432293}}\n",
      "{'diag': 0.5544303797468354, 'pn': 0.4481012658227848, 'str': 0.6506329113924051, 'pig': 0.5949367088607594, 'rs': 0.7341772151898734, 'dag': 0.5240506329113924, 'bwv': 0.810126582278481, 'vs': 0.7924050632911392}\n",
      "Current best average ACC: 0.6386\n",
      "Current average AUC: 0.7473\n",
      "\n",
      "Epoch 4 begin train...\n",
      "Epoch: 4 train loss, Diag loss: 1.2172, PN loss: 0.9807, STR loss: 0.7589, PIG loss: 0.7825, RS loss: 0.4650, DaG loss: 0.9906, BWV loss: 0.4443, VS loss: 0.5033\n",
      "0.6566455696202532 0.8042918659292956\n",
      "Train metics on epoch 4:\n",
      "{'diag': {0: 0.5821240105540897, 1: 0.49488895807388955, 2: 0.4280999528524281, 3: 0.5988732394366197, 4: 0.60008398656215, 'micro': 0.8077759974363082, 'macro': 0.5425842338381834}, 'pn': {0: 0.7228569895933912, 1: 0.6865819442152171, 2: 0.7592038738161362, 'micro': 0.7180035250761094, 'macro': 0.724767651171937}, 'str': {0: 0.8026560649636272, 1: 0.7504532504532504, 2: 0.806354704177564, 'micro': 0.855526357955456, 'macro': 0.7887892000904703}, 'pig': {0: 0.8770205443737616, 1: 0.8392771373679155, 2: 0.8723663849541721, 'micro': 0.8438775837205575, 'macro': 0.8644113371326344}, 'rs': {0: 0.8862375138734739, 1: 0.8862375138734739, 'micro': 0.884787694279763, 'macro': 0.8892620530917524}, 'dag': {0: 0.7118983050847457, 1: 0.6653001284953802, 2: 0.7262996941896025, 'micro': 0.7125717032526838, 'macro': 0.7029528390342684}, 'bwv': {0: 0.7514166666666665, 1: 0.7514166666666667, 'micro': 0.8874731613523474, 'macro': 0.7553086371527777}, 'vs': {0: 0.9363360087274994, 1: 0.9286274949540255, 2: 0.9210045662100457, 'micro': 0.9584041019067456, 'macro': 0.9305159601670329}}\n",
      "{'diag': 0.5544303797468354, 'pn': 0.5189873417721519, 'str': 0.6531645569620254, 'pig': 0.6354430379746835, 'rs': 0.7569620253164557, 'dag': 0.5316455696202531, 'bwv': 0.810126582278481, 'vs': 0.7924050632911392}\n",
      "Current best average ACC: 0.6566\n",
      "Current average AUC: 0.8043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=4)\n",
    "record_acc = 0.\n",
    "record_auc = 0.\n",
    "\n",
    "from time import time\n",
    "total_time_train = 0\n",
    "for epoch in range(5):\n",
    "        # training\n",
    "        start_time_epoch_train = time()\n",
    "\n",
    "        print(\"Epoch {} begin train...\".format(epoch))\n",
    "        pred_all_train, label_true_train = train_func(trainloader, \n",
    "                cnn_c, \n",
    "                cnn_d, \n",
    "                concate_net, \n",
    "                reconstruct_net_c, \n",
    "                reconstruct_net_d, \n",
    "                optimizer, \n",
    "                criterion, \n",
    "                device, \n",
    "                epoch\n",
    "            )\n",
    "        auc_all_train, acc_all_train, con_all_train = metric(pred_all_train, label_true_train, show=False)\n",
    "        avg_acc = get_average_acc(acc_all_train)# get the average acc\n",
    "        avg_auc = get_average_auc(auc_all_train)\n",
    "        con_metric = get_confusion_matrix(pred_all_train, label_true_train) # compute recall and precision\n",
    "        specificity = get_specificity(pred_all_train, label_true_train)\n",
    "        # sens, spec, prec = get_confusion_matrix(con_all_test)\n",
    "        print(avg_acc, avg_auc)\n",
    "        # if i % 10 == 0 or i == (epochs - 1):\n",
    "        if (record_acc+record_auc) <= (avg_acc + avg_auc):\n",
    "            record_acc = avg_acc\n",
    "            record_auc = avg_auc\n",
    "            print(\"Train metics on epoch {}:\".format(epoch))\n",
    "            print(auc_all_train)\n",
    "            print(acc_all_train)\n",
    "            print(\"Current best average ACC: {:.4f}\".format(avg_acc))\n",
    "            print(\"Current average AUC: {:.4f}\".format(avg_auc))\n",
    "            print()\n",
    "\n",
    "        end_time_epoch_train = time()\n",
    "        epoch_time_train = end_time_epoch_train - start_time_epoch_train\n",
    "        total_time_train += epoch_time_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ed0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bac7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a759936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 begin testing...\n",
      "Epoch: 1 test loss, Diag loss: 0.8220, PN loss: 0.6805, STR loss: 0.5907, PIG loss: 0.7436, RS loss: 0.3653, DaG loss: 0.8746, BWV loss: 0.2866, VS loss: 0.4405\n",
      "0.7591772151898735 0.8473625607985668\n",
      "Test metics on epoch 1:\n",
      "{'diag': {0: 0.941787598944591, 1: 0.8965338314653383, 2: 0.8903482184953189, 3: 0.9059859154929577, 4: 0.8171892497200448, 'micro': 0.9339560967793622, 'macro': 0.8917050790802882}, 'pn': {0: 0.8919912026606587, 1: 0.8449139021840788, 2: 0.8205155593534144, 'micro': 0.8611632751161672, 'macro': 0.8542629397745594}, 'str': {0: 0.8300625951615632, 1: 0.8954286454286454, 2: 0.8072736269173676, 'micro': 0.8978464989585003, 'macro': 0.8462718635554005}, 'pig': {0: 0.8073573886745229, 1: 0.8515249759846302, 2: 0.8338590643970956, 'micro': 0.8701778561128024, 'macro': 0.8326071577107976}, 'rs': {0: 0.8676633805575505, 1: 0.8676633805575504, 'micro': 0.9067841692036532, 'macro': 0.8704126520852186}, 'dag': {0: 0.7717627118644068, 1: 0.7767851679618185, 2: 0.8191831234126367, 'micro': 0.8018170165037655, 'macro': 0.7909886447540199}, 'bwv': {0: 0.9107916666666667, 1: 0.9107916666666667, 'micro': 0.953257490786733, 'macro': 0.9131359917534722}, 'vs': {0: 0.8958544377776045, 1: 0.8876990356582193, 2: 0.8087671232876712, 'micro': 0.9475692997917, 'macro': 0.867285975559729}}\n",
      "{'diag': 0.7544303797468355, 'pn': 0.7037974683544304, 'str': 0.7468354430379747, 'pig': 0.7088607594936709, 'rs': 0.8075949367088607, 'dag': 0.6379746835443038, 'bwv': 0.8810126582278481, 'vs': 0.8329113924050633}\n",
      "Current best average ACC: 0.7592\n",
      "Current average AUC: 0.8474\n"
     ]
    }
   ],
   "source": [
    "record_acc = 0.\n",
    "record_auc = 0.\n",
    "\n",
    "model_name_c = './checkpoint/feature_extraction_c_fusion_9-12_21.pth'# './checkpoint/feature_extraction_concate_discrinimator_0713_c1_two_stream.pth' # 3 ahieved the best performance \n",
    "model_name_d = './checkpoint/feature_extraction_d_fusion_9-12_21.pth' #'./checkpoint/feature_extraction_concate_discrinimator_0713_d1_two_stream.pth'\n",
    "model_name_concate = './checkpoint/concatenate_fusion_9-12_21.pth'# './checkpoint/concate_discrinimator_0713_concatenate1_two_stream.pth'\n",
    "model_name_dis_c = './checkpoint/discriminator_fusion_9-12_21.pth'# './checkpoint/reconstruct_concate_discrinimator_0713_c1_two_stream.pth'\n",
    "model_name_recon_c = './checkpoint/reconstruct_c_fusion_9-12_21.pth'# './checkpoint/feature_extraction_concate_recon_0713_c1_two_stream.pth' # 3 ahieved the best performance\n",
    "model_name_recon_d = './checkpoint/reconstruct_c_fusion_9-12_21.pth'# './checkpoint/feature_extraction_concate_recon_0713_d1_two_stream.pth'\n",
    "\n",
    "checkpoint_c = torch.load(model_name_c)\n",
    "cnn_c.load_state_dict(checkpoint_c)\n",
    "checkpoint_d = torch.load(model_name_d)\n",
    "cnn_d.load_state_dict(checkpoint_d)\n",
    "checkpoint_concate_net = torch.load(model_name_concate)\n",
    "concate_net.load_state_dict(checkpoint_concate_net)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=48,\n",
    "                                              shuffle=False, num_workers=4)\n",
    "i=1\n",
    "print(\"Epoch {} begin testing...\".format(i))\n",
    "pred_all_test, label_true_test = test_func(testloader, \n",
    "                        cnn_c, \n",
    "                        cnn_d, \n",
    "                        concate_net, \n",
    "                        reconstruct_net_c, \n",
    "                        reconstruct_net_d, \n",
    "                        criterion,\n",
    "                        device,\n",
    "                        i)\n",
    "auc_all_test, acc_all_test, con_all_test = metric(pred_all_test, label_true_test, show=False)\n",
    "avg_acc = get_average_acc(acc_all_test)# get the average acc\n",
    "avg_auc = get_average_auc(auc_all_test)\n",
    "con_metric = get_confusion_matrix(pred_all_test, label_true_test) # compute recall and precision\n",
    "specificity = get_specificity(pred_all_test, label_true_test)\n",
    "# sens, spec, prec = get_confusion_matrix(con_all_test)\n",
    "print(avg_acc, avg_auc)\n",
    "# if i % 10 == 0 or i == (epochs - 1):\n",
    "if (record_acc+record_auc) <= (avg_acc + avg_auc):\n",
    "    record_acc = avg_acc\n",
    "    record_auc = avg_auc\n",
    "    print(\"Test metics on epoch {}:\".format(i))\n",
    "    print(auc_all_test)\n",
    "    print(acc_all_test)\n",
    "    print(\"Current best average ACC: {:.4f}\".format(avg_acc))\n",
    "    print(\"Current average AUC: {:.4f}\".format(avg_auc))\n",
    "    # print('confusion_matrix' + str(con_metric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e9dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
