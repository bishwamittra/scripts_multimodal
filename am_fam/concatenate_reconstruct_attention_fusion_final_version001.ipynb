{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-syntax",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishwa/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import sys, os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch, torchvision\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "from dalib.modules import WarmStartGradientReverseLayer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tamil-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 19:26:31.155537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 19:26:31.314886: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-02 19:26:31.924030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-02 19:26:31.924100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-02 19:26:31.924106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from derm7pt.dataset import Derm7PtDataset, Derm7PtDatasetGroupInfrequent\n",
    "from derm7pt.vis import plot_confusion\n",
    "from derm7pt.kerasutils import deep_features\n",
    "dir_release = '../data/release_v0'\n",
    "dir_meta = os.path.join(dir_release, 'meta')\n",
    "dir_images = os.path.join(dir_release, 'images')\n",
    "meta_df = pd.read_csv(os.path.join(dir_meta, 'meta.csv'))\n",
    "train_indexes = list(pd.read_csv(os.path.join(dir_meta, 'train_indexes.csv'))['indexes'])\n",
    "valid_indexes = list(pd.read_csv(os.path.join(dir_meta, 'valid_indexes.csv'))['indexes'])\n",
    "test_indexes = list(pd.read_csv(os.path.join(dir_meta, 'test_indexes.csv'))['indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saved-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full dataset before any grouping of the labels.\n",
    "derm_data = Derm7PtDataset(dir_images=dir_images, \n",
    "                        metadata_df=meta_df.copy(), # Copy as is modified.\n",
    "                        train_indexes=train_indexes, valid_indexes=valid_indexes, \n",
    "                        test_indexes=test_indexes)\n",
    "\n",
    "# The dataset after grouping infrequent labels.\n",
    "derm_data_group = Derm7PtDatasetGroupInfrequent(dir_images=dir_images, \n",
    "                                             metadata_df=meta_df.copy(), # Copy as is modified.\n",
    "                                             train_indexes=train_indexes, \n",
    "                                             valid_indexes=valid_indexes, \n",
    "                                             test_indexes=test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "published-fellow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 1011\n",
      "Number of cases to train: 413\n",
      "Number of cases to validate: 203\n",
      "Number of cases to test: 395\n"
     ]
    }
   ],
   "source": [
    "derm_data.dataset_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regular-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../data/release_v0/images/'\n",
    "BCC = ['basal cell carcinoma'] \n",
    "NEV = ['blue nevus', 'clark nevus', 'combined nevus', 'congenital nevus', 'dermal nevus', 'recurrent nevus', 'reed or spitz nevus']\n",
    "MEL = ['melanoma', 'melanoma (in situ)', 'melanoma (less than 0.76 mm)', 'melanoma (0.76 to 1.5 mm)', 'melanoma (more than 1.5 mm)', 'melanoma metastasis' ]\n",
    "MISC = ['dermatofibroma', 'lentigo', 'melanosis', 'miscellaneous', 'vascular lesion']\n",
    "SK = ['seborrheic keratosis']\n",
    "PN = {'absent':0, 'typical':1, 'atypical':2}\n",
    "STR = {'absent':0, 'regular':1, 'irregular':2}\n",
    "PIG = {'absent':0, 'diffuse regular':1, 'localized regular':1, 'diffuse irregular':2, 'localized irregular':2}\n",
    "RS = {'absent':0, 'blue areas':1, 'white areas':1, 'combinations':1}\n",
    "DaG = {'absent':0, 'regular':1, 'irregular':2}\n",
    "BWV = {'absent':0, 'present':1}\n",
    "VS = {'absent':0, 'arborizing':1, 'comma':1, 'hairpin':1, 'within regression':1, 'wreath':1, 'dotted':2, 'linear irregular':2}\n",
    "def get_diag_label(diag):\n",
    "    if diag in BCC:\n",
    "        label = 0\n",
    "    elif diag in NEV:\n",
    "        label = 1\n",
    "    elif diag in MEL:\n",
    "        label = 2\n",
    "    elif diag in MISC:\n",
    "        label = 3\n",
    "    elif diag in SK:\n",
    "        label = 4\n",
    "    if label == None:\n",
    "        print(\"Error!\")\n",
    "    else:\n",
    "        return label\n",
    "def get_7point_label(point_criteria):\n",
    "    label0 = PN[point_criteria[0]]\n",
    "    label1 = STR[point_criteria[1]]\n",
    "    label2 = PIG[point_criteria[2]]\n",
    "    label3 = RS[point_criteria[3]]\n",
    "    label4 = DaG[point_criteria[4]]\n",
    "    label5 = BWV[point_criteria[5]]\n",
    "    label6 = VS[point_criteria[6]]\n",
    "    return [label0, label1, label2, label3, label4, label5, label6]\n",
    "clinic_train = []\n",
    "clinic_validate = []\n",
    "clinic_test = []\n",
    "dermoscopic_train = []\n",
    "dermoscopic_validate = []\n",
    "dermoscopic_test = []\n",
    "label_train_diag = []\n",
    "label_validate_diag = []\n",
    "label_test_diag = []\n",
    "label_train_crit = []\n",
    "label_validate_crit = []\n",
    "label_test_crit = []\n",
    "for index, row in meta_df.iterrows():\n",
    "    c_img = row[15]\n",
    "    d_img = row[16]\n",
    "    diag = row[1]\n",
    "    p_n = row[3]\n",
    "    s_t_r = row[4]\n",
    "    p_i_g = row[5]\n",
    "    r_s = row[6]\n",
    "    d_a_g = row[7]\n",
    "    b_w_v = row[8]\n",
    "    v_s = row[9]\n",
    "    point_criteria = [p_n, s_t_r, p_i_g, r_s, d_a_g, b_w_v, v_s]\n",
    "    # if d_img == 'FCl/Fcl068.jpg':\n",
    "    #     d_img = 'FCL/Fcl068.jpg'\n",
    "\n",
    "    if index in train_indexes:        \n",
    "        clinic_train.append(img_path + c_img)\n",
    "        dermoscopic_train.append(img_path + d_img)\n",
    "        label_train_diag.append(get_diag_label(diag))\n",
    "        label_train_crit.append(get_7point_label(point_criteria))\n",
    "    elif index in valid_indexes:\n",
    "        clinic_validate.append(img_path + c_img)\n",
    "        dermoscopic_validate.append(img_path + d_img)\n",
    "        label_validate_diag.append(get_diag_label(diag))\n",
    "        label_validate_crit.append(get_7point_label(point_criteria))\n",
    "    elif index in test_indexes:\n",
    "        clinic_test.append(img_path + c_img)\n",
    "        dermoscopic_test.append(img_path + d_img)\n",
    "        label_test_diag.append(get_diag_label(diag))\n",
    "        label_test_crit.append(get_7point_label(point_criteria))\n",
    "    else:\n",
    "        print(\"There is an error need to be fixed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efficient-tuning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_indexes.sort()\n",
    "# valid_indexes.sort()\n",
    "# print(train_indexes)\n",
    "# print(valid_indexes)\n",
    "# print(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arranged-background",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 203 395\n"
     ]
    }
   ],
   "source": [
    "print(len(clinic_train), len(clinic_validate), len(clinic_test))\n",
    "# print(clinic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optical-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_c = Image.open(self.data.c_path[idx])\n",
    "        img_c = img_c.convert(\"RGB\")\n",
    "        img_c = self.transform(img_c)\n",
    "        img_d = Image.open(self.data.d_path[idx])\n",
    "        img_d = img_d.convert(\"RGB\")\n",
    "        img_d = self.transform(img_d)\n",
    "        \n",
    "        label_diag_i = np.array(self.data.lab_diag[idx])\n",
    "        \n",
    "        label_crit_i = np.array(self.data.lab_crit[idx])\n",
    "        \n",
    "        return img_c, img_d, label_diag_i, label_crit_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66269380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_train_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31663aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sample_count = np.array([len(np.where(label_train_diag == t)[0]) for t in np.unique(label_train_diag)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in label_train_diag])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "# sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rural-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize([299, 299]),\n",
    "                                       transforms.Pad(padding=20, fill=(0, 0, 0)),\n",
    "                                       transforms.RandomCrop([299, 299]),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation([-45, 45]),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]) #(0.5 , 0.5 , 0.5), (0.5 , 0.5 , 0.5)\n",
    "test_transforms = transforms.Compose([transforms.Resize([299, 299]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) # (0.5 , 0.5 , 0.5), (0.5 , 0.5 , 0.5)\n",
    "])\n",
    "image_transforms = {'train':train_transforms, 'test':test_transforms}\n",
    "\n",
    "train = list(zip(clinic_train, dermoscopic_train, label_train_diag, label_train_crit))\n",
    "train_df = pd.DataFrame(train, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "train_dataset = MyDataset(train_df, transform=image_transforms['train'])\n",
    "\n",
    "validate = list(zip(clinic_validate, dermoscopic_validate, label_validate_diag, label_validate_crit))\n",
    "validate_df = pd.DataFrame(validate, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "validate_dataset = MyDataset(validate_df, transform=image_transforms['test'])\n",
    "\n",
    "test = list(zip(clinic_test, dermoscopic_test, label_test_diag, label_test_crit))\n",
    "test_df = pd.DataFrame(test, columns=['c_path','d_path','lab_diag', 'lab_crit'])\n",
    "test_dataset = MyDataset(test_df, transform=image_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "false-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_auc(pre, true, show = False):\n",
    "    auc_all = {}\n",
    "    for key in pre.keys():\n",
    "        n_classes = np.array(pre[key]).shape[-1]\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        one_hot = torch.zeros(len(true[key]), n_classes).scatter_(1, torch.tensor(np.array(true[key]).reshape(len(np.array(true[key])), 1)), 1)\n",
    "        for i in range(n_classes):\n",
    "            # fpr[i], tpr[i], _ = roc_curve(one_hot[:, i], np.array(pre[key])[:, i])\n",
    "            fpr[i], tpr[i], _ = roc_curve(one_hot[:, i], np.array(nn.Softmax(dim=1)(torch.Tensor(pre[key])))[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        # Compute micro-average ROC curve and ROC area（方法二）\n",
    "        # fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.array(one_hot).ravel(), np.array(pre[key]).ravel())\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.array(one_hot).ravel(), np.array(nn.Softmax(dim=1)(torch.Tensor(pre[key]))).ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Compute macro-average ROC curve and ROC area（方法一）\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "        \n",
    "        if show == True:\n",
    "            # Plot all ROC curves\n",
    "            color_list = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'brown']\n",
    "            lw=2\n",
    "            plt.figure()\n",
    "            plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                     label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                           ''.format(roc_auc[\"micro\"]),\n",
    "                     color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "            plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                     label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                           ''.format(roc_auc[\"macro\"]),\n",
    "                     color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "            colors = cycle(color_list[0:n_classes])\n",
    "            for i, color in zip(range(n_classes), colors):\n",
    "                plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                         label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                         ''.format(i, roc_auc[i]))\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "        auc_all[key] = roc_auc\n",
    "    return auc_all\n",
    "\n",
    "def cal_con_matrix(pre, true):\n",
    "    acc_all = {}\n",
    "    con_all = {}\n",
    "    tp_fp = {}\n",
    "    for key in pre.keys():\n",
    "        acc = accuracy_score(np.array(true[key]), np.argmax(np.array(pre[key]), axis=-1))\n",
    "        con = confusion_matrix(np.array(true[key]), np.argmax(np.array(pre[key]), axis=-1))\n",
    "        acc_all[key] = acc\n",
    "        con_all[key] = con\n",
    "    return acc_all, con_all\n",
    "\n",
    "def metric(pre, true, show = False):\n",
    "    auc_all = cal_auc(pre=pre, true=true, show = show)\n",
    "    acc_all, con_all = cal_con_matrix(pre=pre, true=true)\n",
    "    return auc_all, acc_all, con_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")# (\"cuda:0\")\n",
    "class CNN(nn.Module): \n",
    "    def __init__(self, model):\n",
    "        super(CNN, self).__init__()\n",
    "        self.resnet_layer = nn.Sequential(*list(model.children())[:-2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.resnet_layer(x)\n",
    "        return x\n",
    "class Concate(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Concate, self).__init__()\n",
    "        self.hidden_size = 512 # 512\n",
    "        \n",
    "        self.avp_pooling = nn.AdaptiveAvgPool2d((1, 1)) # AdaptiveAvgPool2d\n",
    "        self.linear_layer1 = nn.Linear(2048 * 2, self.hidden_size) # reduce the dimensional\n",
    "        \n",
    "        # attention computation using SEblock\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 2048 // 2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048 // 2, 2048, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.att_relu = nn.ReLU()\n",
    "        \n",
    "        # define classifiers\n",
    "        self.out_diag = nn.Linear(self.hidden_size, 5)\n",
    "        self.out_crit_pn = nn.Linear(self.hidden_size, 3) # p_n 3, s_t_r 3, p_i_g 3, r_s 2, d_a_g 3, b_w_v 2, v_s 3\n",
    "        self.out_crit_str = nn.Linear(self.hidden_size, 3)\n",
    "        self.out_crit_pig = nn.Linear(self.hidden_size, 3)\n",
    "        self.out_crit_rs = nn.Linear(self.hidden_size, 2)\n",
    "        self.out_crit_dag = nn.Linear(self.hidden_size, 3)\n",
    "        self.out_crit_bwv = nn.Linear(self.hidden_size, 2)\n",
    "        self.out_crit_vs = nn.Linear(self.hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, x_c, x_d):\n",
    "        b, c, _, _ = x_c.size()\n",
    "        img_size = torch.rand(x_c.size()[0], 3, x_c.size()[2], x_c.size()[3])\n",
    "        # SE feature compute\n",
    "        x_att_c = self.avg_pool(x_c).view(b, c)\n",
    "        x_att_c = self.fc(x_att_c).view(b, c, 1, 1)\n",
    "        x_att_feature_c = x_c * x_att_c.expand_as(x_c)\n",
    "        \n",
    "        x_att_d = self.avg_pool(x_d).view(b, c)\n",
    "        x_att_d = self.fc(x_att_d).view(b, c, 1, 1)\n",
    "        x_att_feature_d = x_d * x_att_d.expand_as(x_d)\n",
    "        \n",
    "        x_concat = torch.cat((x_c, x_d), dim=1)# x_att_feature_c, x_att_feature_d\n",
    "         \n",
    "        x_att_mask_c = torch.sum(x_c, dim=1) # x_att_feature_c\n",
    "        x_att_mask_d = torch.sum(x_d, dim=1)\n",
    "        # x_att_mask_c = x_att_c\n",
    "        # x_att_mask_d = x_att_d\n",
    "        x_att_mask_c = (x_att_mask_c - x_att_mask_c.min())/(x_att_mask_c.max() - x_att_mask_c.min()) #  (x - X_min) / (X_max - X_min)\n",
    "        x_att_mask_d = (x_att_mask_d - x_att_mask_d.min())/(x_att_mask_d.max() - x_att_mask_d.min())\n",
    "        # x_att_mask_c = torch.sum(x_att_feature_c, dim=1) / torch.sum(x_att_feature_c, dim=1).max()\n",
    "        # x_att_mask_d = torch.sum(x_att_feature_d, dim=1) / torch.sum(x_att_feature_d, dim=1).max()\n",
    "        x_att_mask_c = nn.functional.interpolate(x_att_mask_c.view(x_c.size()[0], 1, x_c.size()[2], x_c.size()[3]), size=(299, 299), mode='bilinear', align_corners=False) # bicubic, align_corners=False\n",
    "        x_att_mask_d = nn.functional.interpolate(x_att_mask_d.view(x_d.size()[0], 1, x_d.size()[2], x_d.size()[3]), size=(299, 299), mode='bilinear', align_corners=False) # bicubic, align_corners=False\n",
    "        \n",
    "        # flatten feature vectors\n",
    "        x = self.avp_pooling(x_concat).view(x_c.size()[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.linear_layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        # classifiers\n",
    "        x_diag = self.out_diag(x)\n",
    "        x_crit_pn = self.out_crit_pn(x)\n",
    "        x_crit_str = self.out_crit_str(x)\n",
    "        x_crit_pig = self.out_crit_pig(x)\n",
    "        x_crit_rs = self.out_crit_rs(x)\n",
    "        x_crit_dag = self.out_crit_dag(x)\n",
    "        x_crit_bwv = self.out_crit_bwv(x)\n",
    "        x_crit_vs = self.out_crit_vs(x)\n",
    "        return x_diag, x_crit_pn, x_crit_str, x_crit_pig, x_crit_rs, x_crit_dag, x_crit_bwv, x_crit_vs, x_att_mask_c, x_att_mask_d, x_concat\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_size = 256\n",
    "        self.grl = WarmStartGradientReverseLayer(alpha=1., lo=0., hi=1., max_iters=100, auto_step=True) \n",
    "        self.hidden_layer = nn.Linear(2048, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x_c, x_d):\n",
    "        x = torch.cat((x_c, x_d), dim = 0)\n",
    "        x = self.avg_pool(x).view(x.size()[0], -1)\n",
    "        x = self.grl(x)\n",
    "        x = self.relu(self.hidden_layer(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "# resnet501 = models.resnet50(pretrained=True)\n",
    "cnn_c = CNN(resnet50).to(device)\n",
    "cnn_d = CNN(resnet50).to(device)\n",
    "concate_net = Concate().to(device)\n",
    "discriminator = Discriminator().to(device)# 判别分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-buyer",
   "metadata": {},
   "source": [
    "# Attention based reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dated-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight, 0.0, 0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "class ReconstructionNet(nn.Module):\n",
    "    def __init__(self, in_feature, output_size):\n",
    "        super(ReconstructionNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.up1 = nn.Sequential(\n",
    "                               nn.Upsample(scale_factor=4, mode='bicubic', align_corners=True),\n",
    "                               nn.Conv2d(in_feature, 128, 3, bias=False),\n",
    "                               nn.BatchNorm2d(128),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "                               nn.Upsample(scale_factor=4, mode='bicubic', align_corners=True),\n",
    "                               nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "        self.up3 = nn.Sequential(\n",
    "                               nn.Upsample(scale_factor=2, mode='bicubic', align_corners=True),\n",
    "                               nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                               nn.BatchNorm2d(32),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.Sigmoid = nn.Tanh() # nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.final_conv =nn.Conv2d(32, 3, 3, padding=1) # , padding=1\n",
    "        # self.final_conv1 =nn.Conv2d(32, 3, kernel_size = 1) # , padding=1\n",
    "        self.final_BN = nn.BatchNorm2d(3)\n",
    "        self.seg_layers = nn.Sequential(self.up1, self.up2, self.up3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seg_layers(x)\n",
    "        x = nn.functional.interpolate(x, size=self.output_size, mode='bicubic', align_corners=True)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_BN(x)\n",
    "        # x = self.final_conv1(x)\n",
    "        y = self.Sigmoid(x)\n",
    "        # y = (torch.sin(x) + 1)/2.\n",
    "        return y\n",
    "\n",
    "    def get_parameters(self):\n",
    "        parameter_list = [{\"params\":self.parameters(), \"lr_mult\":1, 'decay_mult':2}]\n",
    "        return parameter_list\n",
    "\n",
    "'''def reconstruction_loss(pred=None, ground_truth=None, mask=None, crit=None):\n",
    "    pred1 = pred.view(pred.size()[0], -1)\n",
    "    ground_truth1 = pred.view(ground_truth.size()[0], -1)\n",
    "    \n",
    "    loss = crit(pred.view(pred.size()[0], -1),  ground_truth.view(ground_truth.size()[0], -1))\n",
    "    return loss '''\n",
    "def reconstruction_loss(pred=None, ground_truth=None, mask=None, crit=None):\n",
    "    '''import pdb;\n",
    "    pdb.set_trace()'''\n",
    "    pred1 = pred.view(pred.size()[0], -1)\n",
    "    ground_truth1 = pred.view(ground_truth.size()[0], -1)\n",
    "    \n",
    "    loss = crit(pred.view(pred.size()[0], -1),  ground_truth.view(ground_truth.size()[0], -1))\n",
    "    if mask != None:\n",
    "        mask1 = torch.cat((mask, mask, mask), 1)\n",
    "        mask1 = mask1.view(pred.size()[0], -1).detach()\n",
    "        # weighted loss \n",
    "        loss = loss * torch.exp(mask1) # torch.exp()\n",
    "    loss = torch.mean(torch.sum(loss, dim=1) / loss.size()[1]) # sum or mean\n",
    "    return loss \n",
    "def show_reconstruction_batch(batch_img, mask = False): # show orignal images, attention maps and reconstruction images in one batch\n",
    "    if mask == False:\n",
    "        grid_img = torchvision.utils.make_grid(batch_img, nrow=4)\n",
    "        plt.imshow(grid_img.permute(1, 2, 0).squeeze())\n",
    "        plt.show()\n",
    "    elif mask == True:\n",
    "        # import pdb;pdb.set_trace() # torch.Size([13, 1, 299, 299])\n",
    "        grid_img = torchvision.utils.make_grid(batch_img, nrow=4)\n",
    "        plt.imshow(grid_img.permute(1, 2, 0).squeeze())\n",
    "        plt.show()\n",
    "    \n",
    "reconstruct_net_c = ReconstructionNet(in_feature=2048 * 2, output_size=(299, 299)).to(device)\n",
    "reconstruct_net_d = ReconstructionNet(in_feature=2048 * 2, output_size=(299, 299)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "detailed-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "class MultiFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "        Focal_Loss= -1*alpha*(1-pt)^gamma*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "                    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True):\n",
    "        super(MultiFocalLoss, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if self.alpha is None:\n",
    "            self.alpha = torch.ones(self.num_class, 1)\n",
    "        elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "            assert len(self.alpha) == self.num_class\n",
    "            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "            self.alpha = self.alpha / self.alpha.sum()\n",
    "        elif isinstance(self.alpha, float):\n",
    "            alpha = torch.ones(self.num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[balance_index] = self.alpha\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        # N = input.size(0)\n",
    "        # alpha = torch.ones(N, self.num_class)\n",
    "        # alpha = alpha * (1 - self.alpha)\n",
    "        # alpha = alpha.scatter_(1, target.long(), self.alpha)\n",
    "        epsilon = 1e-10\n",
    "        alpha = self.alpha\n",
    "        if alpha.device != input.device:\n",
    "            alpha = alpha.to(input.device)\n",
    "\n",
    "        idx = target.cpu().long()\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth, 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "        logpt = pt.log()\n",
    "\n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "\n",
    "def get_scheduler(optimizer, lr_policy):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "        Parameters:\n",
    "        optimizer -- 网络优化器\n",
    "        opt.lr_policy -- 学习率scheduler的名称: linear | step | plateau | cosine\n",
    "    \"\"\"\n",
    "    # orch.optim.lr_scheduler.MultiStepLR\n",
    "    if lr_policy == 'linear':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n",
    "            return lr_l\n",
    "\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif lr_policy == 'step':\n",
    "        print(\"Using step schedular!\")\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    elif lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, threshold=1e-2, patience=4)\n",
    "    elif lr_policy == 'cosine':\n",
    "        print(\"Using cosine schedular!\")\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=150, eta_min=1e-8)\n",
    "    elif lr_policy == 'multi':\n",
    "        print(\"Using multi step schedular!\")\n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[20, 50, 100], gamma=0.2) # (optimizer, milestones=[35, 80, 120], gamma=0.5)\n",
    "    elif lr_policy == 'warmstart':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, 2)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler\n",
    "    \n",
    "learning_rate = 1e-5\n",
    "learning_rate_re = 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion1 = MultiFocalLoss(num_class = 2, gamma=2)# nn.CrossEntropyLoss()\n",
    "criterion2 = MultiFocalLoss(num_class = 3, gamma=2)# nn.CrossEntropyLoss()\n",
    "criterion3 = MultiFocalLoss(num_class = 5, gamma=2)# nn.CrossEntropyLoss()\n",
    "opt_list = chain(cnn_c.parameters(), cnn_d.parameters(), concate_net.parameters(), reconstruct_net_c.parameters(), reconstruct_net_d.parameters(), discriminator.parameters())\n",
    "# optimizer = optim.Adam(chain(reconstruct_net_c.parameters(), reconstruct_net_d.parameters(), concate_net.parameters(), cnn_c.parameters(), cnn_d.parameters()), lr=learning_rate , weight_decay=0.0001) #\n",
    "optimizer = optim.AdamW(opt_list, lr=learning_rate, weight_decay=0.0001) # , weight_decay=0.0001\n",
    "# optimizer_con = optim.Adam(chain(concate_net.parameters(), discriminator.parameters()), lr=learning_rate) # , weight_decay=0.0001\n",
    "# optimizer_re = optim.Adam(chain(reconstruct_net_c.parameters(), reconstruct_net_d.parameters()), lr=learning_rate_re) # , weight_decay=0.0001\n",
    "# criterion_recon = nn.MSELoss()\n",
    "scheduler = get_scheduler(optimizer, 'warmstart')\n",
    "criterion_recon = nn.MSELoss(reduction='none')\n",
    "criterion_l1 = nn.L1Loss(reduction='none')\n",
    "def generate_label(batch_size):\n",
    "    l_c = torch.zeros(batch_size)\n",
    "    l_d = torch.ones(batch_size)\n",
    "    label = torch.cat((l_c, l_d), dim=0)\n",
    "    return label\n",
    "def train_fun(dataloader, model_c, model_d, model_concate, model_recon_c, model_recon_d, epoch):\n",
    "    model_c.train()\n",
    "    model_d.train()\n",
    "    model_concate.train()\n",
    "    model_recon_c.train()\n",
    "    model_recon_d.train()\n",
    "    loss_all_count = []\n",
    "    loss_diag_count = []\n",
    "    loss_crit_pn_count = []\n",
    "    loss_crit_str_count = []\n",
    "    loss_crit_pig_count = []\n",
    "    loss_crit_rs_count = []\n",
    "    loss_crit_dag_count = []\n",
    "    loss_crit_bwv_count = []\n",
    "    loss_crit_vs_count = []\n",
    "    loss_recon_c_count = []\n",
    "    loss_recon_d_count = []\n",
    "    loss_discriminator = []\n",
    "    label_true = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    pred_all = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    for index, data in enumerate(dataloader):\n",
    "        # optimizer_re.zero_grad()\n",
    "        # optimizer_con.zero_grad()#\n",
    "        img_c, img_d, lab_diag, lab_crit = data\n",
    "        # print(lab_diag)\n",
    "        label_true['diag'].extend(lab_diag)\n",
    "        img_c, img_d, lab_diag = img_c.to(device), img_d.to(device), lab_diag.to(device)\n",
    "        # import pdb;pdb.set_trace()\n",
    "        label_true['pn'].extend(lab_crit[:, 0]), \\\n",
    "                    label_true['str'].extend(lab_crit[:, 1]), label_true['pig'].extend(lab_crit[:, 2]), label_true['rs'].extend(lab_crit[:, 3]), \\\n",
    "                    label_true['dag'].extend(lab_crit[:, 4]), label_true['bwv'].extend(lab_crit[:, 5]), label_true['vs'].extend(lab_crit[:, 6])\n",
    "        lab_crit_pn, lab_crit_str, lab_crit_pig, lab_crit_rs, lab_crit_dag, lab_crit_bwv, lab_crit_vs = lab_crit[:, 0].to(device), lab_crit[:, 1].to(device), lab_crit[:, 2].to(device), lab_crit[:, 3].to(device), lab_crit[:, 4].to(device), lab_crit[:, 5].to(device), lab_crit[:, 6].to(device)\n",
    "        \n",
    "        #print(lab_crit_dag)\n",
    "        feature_c = cnn_c(img_c)# predict for each class by using two modalities image through concatenate the features\n",
    "        feature_d = cnn_d(img_d)# predict for each class by using two modalities image through concatenate the features\n",
    "        prediction = model_concate(feature_c, feature_d)\n",
    "        out_diag, out_crit_pn, out_crit_str, out_crit_pig, out_crit_rs, out_crit_dag, out_crit_bwv, out_crit_vs, \\\n",
    "                    att_mask_c, att_mask_d, att_feature = prediction\n",
    "        \n",
    "        # reconstrution\n",
    "        recon_pred_c = model_recon_c(att_feature)\n",
    "        recon_pred_d = model_recon_d(att_feature)\n",
    "        recon_loss_c = reconstruction_loss(recon_pred_c, img_c, att_mask_c, crit=criterion_recon) # criterion_l1, criterion_recon\n",
    "        recon_loss_d = reconstruction_loss(recon_pred_d, img_d, att_mask_d, crit=criterion_recon) # criterion_l1, criterion_recon\n",
    "        \n",
    "        # discriminator\n",
    "        label_dis = generate_label(img_c.size()[0]).to(device, dtype=torch.int64)\n",
    "        prediction_domain = discriminator(feature_c, feature_d)\n",
    "        # import pdb;pdb.set_trace()\n",
    "        loss_dis = criterion(prediction_domain, label_dis)\n",
    "        # import pdb;pdb.set_trace()\n",
    "        pred_all['diag'].extend(out_diag.cpu().detach().numpy()), pred_all['pn'].extend(out_crit_pn.cpu().detach().numpy()), \\\n",
    "                        pred_all['str'].extend(out_crit_str.cpu().detach().numpy()), pred_all['pig'].extend(out_crit_pig.cpu().detach().numpy()), pred_all['rs'].extend(out_crit_rs.cpu().detach().numpy()), \\\n",
    "                        pred_all['dag'].extend(out_crit_dag.cpu().detach().numpy()), pred_all['bwv'].extend(out_crit_bwv.cpu().detach().numpy()), pred_all['vs'].extend(out_crit_vs.cpu().detach().numpy())\n",
    "        loss_diag = criterion(out_diag, lab_diag)\n",
    "        loss_crit_pn = criterion(out_crit_pn, lab_crit_pn)\n",
    "        loss_crit_str = criterion(out_crit_str, lab_crit_str)\n",
    "        loss_crit_pig = criterion(out_crit_pig, lab_crit_pig)\n",
    "        loss_crit_rs = criterion(out_crit_rs, lab_crit_rs)\n",
    "        loss_crit_dag = criterion(out_crit_dag, lab_crit_dag)\n",
    "        loss_crit_bwv = criterion(out_crit_bwv, lab_crit_bwv)\n",
    "        loss_crit_vs = criterion(out_crit_vs, lab_crit_vs)\n",
    "        \n",
    "        loss_all = 1/8 * (loss_diag + loss_crit_pn + loss_crit_str + loss_crit_pig + loss_crit_rs + loss_crit_dag + loss_crit_bwv \\\n",
    "                    + loss_crit_vs)  + 0.4 * (recon_loss_c + recon_loss_d) + 0.8 * loss_dis\n",
    "        loss_all.backward()\n",
    "        # optimizer_re.step()\n",
    "        # optimizer_con.step()\n",
    "        optimizer.step()\n",
    "        loss_all_count.append(loss_all.item())\n",
    "        loss_diag_count.append(loss_diag.item())\n",
    "        loss_crit_pn_count.append(loss_crit_pn.item())\n",
    "        loss_crit_str_count.append(loss_crit_str.item())\n",
    "        loss_crit_pig_count.append(loss_crit_pig.item())\n",
    "        loss_crit_rs_count.append(loss_crit_rs.item())\n",
    "        loss_crit_dag_count.append(loss_crit_dag.item())\n",
    "        loss_crit_bwv_count.append(loss_crit_bwv.item())\n",
    "        loss_crit_vs_count.append(loss_crit_vs.item())\n",
    "        loss_recon_c_count.append(recon_loss_c.item())\n",
    "        loss_recon_d_count.append(recon_loss_d.item())\n",
    "        loss_discriminator.append(loss_dis.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    print(\"Epoch: {} train loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}, discriminator loss: {:.4f}\".format(\n",
    "                    epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count), np.average(loss_discriminator)))\n",
    "    log_file.write(\"Epoch: {} train loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}\\n\".format(\n",
    "                    epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count)))\n",
    "    print(\"Reconstruction loss: c_loss: {:.4f}, d_loss: {:.4f}\".format(np.average(loss_recon_c_count), np.average(loss_recon_d_count)))\n",
    "    '''if epoch == 10:\n",
    "        import pdb;pdb.set_trace()\n",
    "        print(\"Debug!\")'''\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        # show the images \n",
    "        # clinical images\n",
    "        show_reconstruction_batch((img_c.detach().cpu() + 1.)/2.)\n",
    "        show_reconstruction_batch(att_mask_c.detach().cpu(), mask = True)\n",
    "        show_reconstruction_batch(recon_pred_c.detach().cpu())\n",
    "        # dermoscopic images\n",
    "        show_reconstruction_batch((img_d.detach().cpu() + 1.)/2.)\n",
    "        show_reconstruction_batch(att_mask_d.detach().cpu(), mask = True)\n",
    "        show_reconstruction_batch(recon_pred_d.detach().cpu())\n",
    "    return pred_all, label_true\n",
    "def validate_fun(dataloader, model_c, model_d, model_concate, model_recon, model_recon_d, epoch):\n",
    "    model_c.eval()\n",
    "    model_d.eval()\n",
    "    model_concate.eval()\n",
    "    loss_diag_count = []\n",
    "    loss_crit_pn_count = []\n",
    "    loss_crit_str_count = []\n",
    "    loss_crit_pig_count = []\n",
    "    loss_crit_rs_count = []\n",
    "    loss_crit_dag_count = []\n",
    "    loss_crit_bwv_count = []\n",
    "    loss_crit_vs_count = []\n",
    "    label_true = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    pred_all = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(dataloader):\n",
    "            img_c, img_d, lab_diag, lab_crit = data\n",
    "            label_true['diag'].extend(lab_diag)\n",
    "            img_c, img_d, lab_diag = img_c.to(device), img_d.to(device), lab_diag.to(device)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            label_true['pn'].extend(lab_crit[:, 0]), \\\n",
    "                        label_true['str'].extend(lab_crit[:, 1]), label_true['pig'].extend(lab_crit[:, 2]), label_true['rs'].extend(lab_crit[:, 3]), \\\n",
    "                        label_true['dag'].extend(lab_crit[:, 4]), label_true['bwv'].extend(lab_crit[:, 5]), label_true['vs'].extend(lab_crit[:, 6])\n",
    "            lab_crit_pn, lab_crit_str, lab_crit_pig, lab_crit_rs, lab_crit_dag, lab_crit_bwv, lab_crit_vs = lab_crit[:, 0].to(device), lab_crit[:, 1].to(device), lab_crit[:, 2].to(device), lab_crit[:, 3].to(device), lab_crit[:, 4].to(device), lab_crit[:, 5].to(device), lab_crit[:, 6].to(device)\n",
    "\n",
    "            # print(lab_crit_dag)\n",
    "            feature_c = model_c(img_c)# predict for each class\n",
    "            feature_d = model_d(img_d)# predict for each class\n",
    "            prediction = model_concate(feature_c, feature_d)\n",
    "\n",
    "            out_diag, out_crit_pn, out_crit_str, out_crit_pig, out_crit_rs, out_crit_dag, out_crit_bwv, out_crit_vs, \\\n",
    "                        att_mask_c, att_mask_d, att_feature = prediction\n",
    "            pred_all['diag'].extend(out_diag.cpu().detach().numpy()), pred_all['pn'].extend(out_crit_pn.cpu().detach().numpy()), \\\n",
    "                            pred_all['str'].extend(out_crit_str.cpu().detach().numpy()), pred_all['pig'].extend(out_crit_pig.cpu().detach().numpy()), pred_all['rs'].extend(out_crit_rs.cpu().detach().numpy()), \\\n",
    "                            pred_all['dag'].extend(out_crit_dag.cpu().detach().numpy()), pred_all['bwv'].extend(out_crit_bwv.cpu().detach().numpy()), pred_all['vs'].extend(out_crit_vs.cpu().detach().numpy())\n",
    "            loss_diag = criterion(out_diag, lab_diag)\n",
    "            loss_crit_pn = criterion(out_crit_pn, lab_crit_pn)\n",
    "            loss_crit_str = criterion(out_crit_str, lab_crit_str)\n",
    "            loss_crit_pig = criterion(out_crit_pig, lab_crit_pig)\n",
    "            loss_crit_rs = criterion(out_crit_rs, lab_crit_rs)\n",
    "            loss_crit_dag = criterion(out_crit_dag, lab_crit_dag)\n",
    "            loss_crit_bwv = criterion(out_crit_bwv, lab_crit_bwv)\n",
    "            loss_crit_vs = criterion(out_crit_vs, lab_crit_vs)\n",
    "            loss_diag_count.append(loss_diag.item())\n",
    "            loss_crit_pn_count.append(loss_crit_pn.item())\n",
    "            loss_crit_str_count.append(loss_crit_str.item())\n",
    "            loss_crit_pig_count.append(loss_crit_pig.item())\n",
    "            loss_crit_rs_count.append(loss_crit_rs.item())\n",
    "            loss_crit_dag_count.append(loss_crit_dag.item())\n",
    "            loss_crit_bwv_count.append(loss_crit_bwv.item())\n",
    "            loss_crit_vs_count.append(loss_crit_vs.item())\n",
    "        print(\"Epoch: {} validate loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}\".format(\n",
    "                        epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count)))\n",
    "        log_file.write(\"Epoch: {} validate loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}\\n\".format(\n",
    "                        epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count)))\n",
    "    return pred_all, label_true\n",
    "\n",
    "def test_fun(dataloader, model_c, model_d, model_concate, model_recon_c, model_recon_d, epoch):\n",
    "    model_c.eval()\n",
    "    model_d.eval()\n",
    "    model_concate.eval()\n",
    "    loss_diag_count = []\n",
    "    loss_crit_pn_count = []\n",
    "    loss_crit_str_count = []\n",
    "    loss_crit_pig_count = []\n",
    "    loss_crit_rs_count = []\n",
    "    loss_crit_dag_count = []\n",
    "    loss_crit_bwv_count = []\n",
    "    loss_crit_vs_count = []\n",
    "    label_true = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    pred_all = {'diag':[], 'pn':[], 'str':[], 'pig':[], 'rs':[], 'dag':[], 'bwv':[], 'vs':[]}\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(dataloader):\n",
    "            img_c, img_d, lab_diag, lab_crit = data\n",
    "            label_true['diag'].extend(lab_diag)\n",
    "            img_c, img_d, lab_diag = img_c.to(device), img_d.to(device), lab_diag.to(device)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            label_true['pn'].extend(lab_crit[:, 0]), \\\n",
    "                        label_true['str'].extend(lab_crit[:, 1]), label_true['pig'].extend(lab_crit[:, 2]), label_true['rs'].extend(lab_crit[:, 3]), \\\n",
    "                        label_true['dag'].extend(lab_crit[:, 4]), label_true['bwv'].extend(lab_crit[:, 5]), label_true['vs'].extend(lab_crit[:, 6])\n",
    "            lab_crit_pn, lab_crit_str, lab_crit_pig, lab_crit_rs, lab_crit_dag, lab_crit_bwv, lab_crit_vs = lab_crit[:, 0].to(device), lab_crit[:, 1].to(device), lab_crit[:, 2].to(device), lab_crit[:, 3].to(device), lab_crit[:, 4].to(device), lab_crit[:, 5].to(device), lab_crit[:, 6].to(device)\n",
    "\n",
    "            # print(lab_crit_dag)\n",
    "            feature_c = model_c(img_c)# predict for each class\n",
    "            feature_d = model_d(img_d)# predict for each class\n",
    "            prediction = model_concate(feature_c, feature_d)\n",
    "            out_diag, out_crit_pn, out_crit_str, out_crit_pig, out_crit_rs, out_crit_dag, out_crit_bwv, out_crit_vs, \\\n",
    "                        att_mask_c, att_mask_d, att_feature = prediction\n",
    "            \n",
    "            recon_pred_c = model_recon_c(att_feature)\n",
    "            recon_pred_d = model_recon_d(att_feature)\n",
    "\n",
    "            pred_all['diag'].extend(out_diag.cpu().detach().numpy()), pred_all['pn'].extend(out_crit_pn.cpu().detach().numpy()), \\\n",
    "                            pred_all['str'].extend(out_crit_str.cpu().detach().numpy()), pred_all['pig'].extend(out_crit_pig.cpu().detach().numpy()), pred_all['rs'].extend(out_crit_rs.cpu().detach().numpy()), \\\n",
    "                            pred_all['dag'].extend(out_crit_dag.cpu().detach().numpy()), pred_all['bwv'].extend(out_crit_bwv.cpu().detach().numpy()), pred_all['vs'].extend(out_crit_vs.cpu().detach().numpy())\n",
    "            loss_diag = criterion(out_diag, lab_diag)\n",
    "            loss_crit_pn = criterion(out_crit_pn, lab_crit_pn)\n",
    "            loss_crit_str = criterion(out_crit_str, lab_crit_str)\n",
    "            loss_crit_pig = criterion(out_crit_pig, lab_crit_pig)\n",
    "            loss_crit_rs = criterion(out_crit_rs, lab_crit_rs)\n",
    "            loss_crit_dag = criterion(out_crit_dag, lab_crit_dag)\n",
    "            loss_crit_bwv = criterion(out_crit_bwv, lab_crit_bwv)\n",
    "            loss_crit_vs = criterion(out_crit_vs, lab_crit_vs)\n",
    "            loss_diag_count.append(loss_diag.item())\n",
    "            loss_crit_pn_count.append(loss_crit_pn.item())\n",
    "            loss_crit_str_count.append(loss_crit_str.item())\n",
    "            loss_crit_pig_count.append(loss_crit_pig.item())\n",
    "            loss_crit_rs_count.append(loss_crit_rs.item())\n",
    "            loss_crit_dag_count.append(loss_crit_dag.item())\n",
    "            loss_crit_bwv_count.append(loss_crit_bwv.item())\n",
    "            loss_crit_vs_count.append(loss_crit_vs.item())\n",
    "        print(\"Epoch: {} test loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}\".format(\n",
    "                        epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count)))\n",
    "        log_file.write(\"Epoch: {} test loss, Diag loss: {:.4f}, PN loss: {:.4f}, STR loss: {:.4f}, PIG loss: {:.4f}, RS loss: {:.4f}, DaG loss: {:.4f}, BWV loss: {:.4f}, VS loss: {:.4f}\\n\".format(\n",
    "                        epoch, np.average(loss_diag_count), np.average(loss_crit_pn_count), np.average(loss_crit_str_count), np.average(loss_crit_pig_count), np.average(loss_crit_rs_count), np.average(loss_crit_dag_count), np.average(loss_crit_bwv_count), np.average(loss_crit_vs_count)))\n",
    "        if epoch % 10 == 0:\n",
    "            # show the images \n",
    "            # clinical images\n",
    "            show_reconstruction_batch((img_c.detach().cpu() + 1.)/2.)\n",
    "            show_reconstruction_batch(att_mask_c.detach().cpu(), mask = True)\n",
    "            show_reconstruction_batch(recon_pred_c.detach().cpu())\n",
    "            # dermoscopic images\n",
    "            show_reconstruction_batch((img_d.detach().cpu() + 1.)/2.)\n",
    "            show_reconstruction_batch(att_mask_d.detach().cpu(), mask = True)\n",
    "            show_reconstruction_batch(recon_pred_d.detach().cpu())\n",
    "    return pred_all, label_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "continent-breath",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 begin training...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m begin training...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[1;32m     61\u001b[0m log_file\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m begin training...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m---> 62\u001b[0m pred_all_train, label_true_train \u001b[39m=\u001b[39m train_fun(trainloader, cnn_c, cnn_d, concate_net, reconstruct_net_c, reconstruct_net_d, i) \n\u001b[1;32m     63\u001b[0m auc_all_train, acc_all_train, con_all_train \u001b[39m=\u001b[39m metric(pred_all_train, label_true_train, show\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m# auc_all, acc_all, con_all\u001b[39;00m\n\u001b[1;32m     64\u001b[0m avg_acc_train \u001b[39m=\u001b[39m get_average_acc(acc_all_train)\u001b[39m# get the average acc\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 182\u001b[0m, in \u001b[0;36mtrain_fun\u001b[0;34m(dataloader, model_c, model_d, model_concate, model_recon_c, model_recon_d, epoch)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39m# discriminator\u001b[39;00m\n\u001b[1;32m    181\u001b[0m label_dis \u001b[39m=\u001b[39m generate_label(img_c\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m--> 182\u001b[0m prediction_domain \u001b[39m=\u001b[39m discriminator(feature_c, feature_d)\n\u001b[1;32m    183\u001b[0m \u001b[39m# import pdb;pdb.set_trace()\u001b[39;00m\n\u001b[1;32m    184\u001b[0m loss_dis \u001b[39m=\u001b[39m criterion(prediction_domain, label_dis)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 93\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x_c, x_d)\u001b[0m\n\u001b[1;32m     91\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x_c, x_d), dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_pool(x)\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrl(x)\n\u001b[1;32m     94\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_layer(x))\n\u001b[1;32m     95\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/dalib/modules/grl.py:67\u001b[0m, in \u001b[0;36mWarmStartGradientReverseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     66\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     coeff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfloat(\n\u001b[1;32m     68\u001b[0m         \u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhi \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlo) \u001b[39m/\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_num \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iters))\n\u001b[1;32m     69\u001b[0m         \u001b[39m-\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhi \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlo) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlo\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_step:\n\u001b[1;32m     72\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multimodal/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "def get_average_acc(acc):\n",
    "    accs = []\n",
    "    for key in acc.keys():\n",
    "        accs.append(acc[key])\n",
    "    avg_acc = np.average(accs)\n",
    "    return avg_acc\n",
    "def get_average_auc(auc):\n",
    "    aucs = []\n",
    "    for key in auc.keys():\n",
    "        if key == 'diag':\n",
    "            continue\n",
    "        else:\n",
    "            for key_i in auc[key].keys():\n",
    "                if key_i == 'micro' or key_i == 'macro':\n",
    "                    continue\n",
    "                else:\n",
    "                    aucs.append(auc[key][key_i])\n",
    "    # print(len(aucs))\n",
    "    avg_auc = np.average(aucs)\n",
    "    return avg_auc\n",
    "def get_specificity(pre, true):\n",
    "    sen = {}\n",
    "    for key in pre:\n",
    "        sen[key] = specificity_score(np.array(pre[key]).argmax(axis=1), true[key], average=None)\n",
    "    return sen\n",
    "def get_confusion_matrix(pre, true): # recall and precision\n",
    "    confusion_metric = {}\n",
    "    for key in pre:\n",
    "        # import pdb;pdb.set_trace()\n",
    "        confusion_metric[key] = classification_report(np.array(pre[key]).argmax(axis=1), true[key], zero_division  = 1, output_dict=True)\n",
    "    return confusion_metric\n",
    "\n",
    "os.system(\"mkdir -p log\")\n",
    "log_file = open('./log/log' + 'concate_reconstruct_attention_fusion_new' + '.txt', 'w', buffering = 1)\n",
    "epochs = 1\n",
    "record_acc = 0.\n",
    "record_auc = 0.\n",
    "\n",
    "record_acc1 = 0.\n",
    "record_auc1 = 0.\n",
    "\n",
    "\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "model_name_c = './checkpoint/feature_extraction_c_fusion_new.pth' # 27-3 ahieved the best performance # 0502-2 record result # 0502-3 best results\n",
    "model_name_d = './checkpoint/feature_extraction_d_fusion_new.pth' #  1-8or9\n",
    "model_name_concate = './checkpoint/concatenate_fusion_new.pth'\n",
    "model_name_reconstruct_c = './checkpoint/reconstruct_c_fusion_new.pth'\n",
    "model_name_reconstruct_d = './checkpoint/reconstruct_d_fusion_new.pth'\n",
    "model_name_discriminator = './checkpoint/discriminator_fusion_new.pth'\n",
    "for i in range(epochs):\n",
    "\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size= 8,\n",
    "                                                  sampler=sampler, num_workers=4)\n",
    "    validateloader = torch.utils.data.DataLoader(validate_dataset, batch_size=48,\n",
    "                                                  shuffle=False, num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=48,\n",
    "                                                  shuffle=False, num_workers=4)\n",
    "    print(\"Epoch {} begin training...\".format(i))\n",
    "    log_file.write(\"Epoch {} begin training...\\n\".format(i))\n",
    "    pred_all_train, label_true_train = train_fun(trainloader, cnn_c, cnn_d, concate_net, reconstruct_net_c, reconstruct_net_d, i) \n",
    "    auc_all_train, acc_all_train, con_all_train = metric(pred_all_train, label_true_train, show=False) # auc_all, acc_all, con_all\n",
    "    avg_acc_train = get_average_acc(acc_all_train)# get the average acc\n",
    "    avg_auc_train = get_average_auc(auc_all_train)\n",
    "    print(avg_acc_train, avg_auc_train)\n",
    "    log_file.write(\"Current average ACC: {:.4f} \\n\".format(avg_acc_train))\n",
    "    log_file.write(\"Current average AUC: {:.4f} \\n\".format(avg_auc_train))\n",
    "#     scheduler.step()\n",
    "    \n",
    "    print(scheduler.get_lr()[0])\n",
    "\n",
    "    print(\"Epoch {} begin validating...\".format(i))\n",
    "    log_file.write(\"Epoch {} begin validating...\\n\".format(i))\n",
    "    pred_all_validate, label_true_validate = validate_fun(validateloader, cnn_c, cnn_d, concate_net, reconstruct_net_c, reconstruct_net_d, i)\n",
    "    auc_all_validate, acc_all_validate, con_all_validate = metric(pred_all_validate, label_true_validate, show=False)\n",
    "    avg_acc_validate = get_average_acc(acc_all_validate)# get the average acc\n",
    "    avg_auc_validate = get_average_auc(auc_all_validate)\n",
    "    print(avg_acc_validate, avg_auc_validate)\n",
    "    log_file.write(\"Current average ACC: {:.4f} \\n\".format(avg_acc_validate))\n",
    "    log_file.write(\"Current average AUC: {:.4f} \\n\".format(avg_auc_validate))\n",
    "\n",
    "    print(\"Epoch {} begin testing...\".format(i))\n",
    "    log_file.write(\"Epoch {} begin testing...\\n\".format(i))\n",
    "    pred_all_test, label_true_test = test_fun(testloader, cnn_c, cnn_d, concate_net, reconstruct_net_c, reconstruct_net_d, i)\n",
    "    auc_all_test, acc_all_test, con_all_test = metric(pred_all_test, label_true_test, show=False)\n",
    "    avg_acc = get_average_acc(acc_all_test)# get the average acc\n",
    "    avg_auc = get_average_auc(auc_all_test)\n",
    "    con_metric = get_confusion_matrix(pred_all_test, label_true_test) # compute recall and precision\n",
    "    specificity = get_specificity(pred_all_test, label_true_test)\n",
    "    # sens, spec, prec = get_confusion_matrix(con_all_test)\n",
    "    # if i % 10 == 0 or i == (epochs - 1):\n",
    "    if (record_acc+record_auc) <= (avg_acc_validate + avg_auc_validate):\n",
    "        record_acc1 = avg_acc_validate\n",
    "        record_auc1 = avg_auc_validate\n",
    "        print(\"Best validate test metics on epoch {}:\".format(i))\n",
    "        print(auc_all_test)\n",
    "        print(acc_all_test)\n",
    "        print(avg_acc)\n",
    "        print(avg_auc)\n",
    "        log_file.write(\"Best validate test metics on epoch {}:\\n\".format(i))\n",
    "        log_file.write(str(auc_all_test) + '\\n')\n",
    "        log_file.write(str(acc_all_test) + '\\n')\n",
    "        log_file.write('confusion_matrix' + str(con_metric) + '\\n')\n",
    "        \n",
    "        torch.save(cnn_c.state_dict(), model_name_c)\n",
    "        torch.save(cnn_d.state_dict(), model_name_d)\n",
    "        torch.save(concate_net.state_dict(), model_name_concate)\n",
    "        torch.save(reconstruct_net_c.state_dict(), model_name_reconstruct_c)\n",
    "        torch.save(reconstruct_net_d.state_dict(), model_name_reconstruct_d)\n",
    "        torch.save(reconstruct_net_d.state_dict(), model_name_discriminator)\n",
    "        \n",
    "        print(\"Test metics on epoch {}:\".format(i))\n",
    "        print(auc_all_test)\n",
    "        print(acc_all_test)\n",
    "        print(avg_acc)\n",
    "        print(avg_auc)\n",
    "        log_file.write(\"Test metics on epoch {}:\\n\".format(i))\n",
    "        log_file.write(str(auc_all_test) + '\\n')\n",
    "        log_file.write(str(acc_all_test) + '\\n')\n",
    "        log_file.write('confusion_matrix' + str(con_metric) + '\\n')\n",
    "        # log_file.write(str(avg_acc))\n",
    "        log_file.write(\"Current average ACC: {:.4f} \\n\".format(avg_acc))\n",
    "        log_file.write(\"Current average AUC: {:.4f} \\n\".format(avg_auc))\n",
    "        # log_file.write(str(avg_auc))\n",
    "\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-catch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b5314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
